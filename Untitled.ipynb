{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024b3ffb-a719-4b36-bd6c-f34ab5466c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfkit\n",
    "from PyPDF2 import PdfMerger\n",
    "import shutil\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ceb1c-1d1c-424e-91e0-5354bbb730fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to wkhtmltopdf executable\n",
    "path_to_wkhtmltopdf = r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe'\n",
    "pdfkit_config = pdfkit.configuration(wkhtmltopdf=path_to_wkhtmltopdf)\n",
    "\n",
    "# Function to get search results\n",
    "def get_search_results(query, num_results=20):\n",
    "    search_url = \"https://www.google.com/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    \n",
    "    response = requests.get(search_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    exclude_domains = [\n",
    "        \"youtube.com\", \"vimeo.com\", \"dailymotion.com\", \"twitch.tv\", \"netflix.com\", \n",
    "        \"hulu.com\", \"disneyplus.com\", \"amazon.com\", \"primevideo.com\"\n",
    "    ]\n",
    "    \n",
    "    links = []\n",
    "    for item in soup.find_all('a'):\n",
    "        href = item.get('href')\n",
    "        if href and \"/url?q=\" in href:\n",
    "            url = href.split(\"/url?q=\")[1].split(\"&sa=U\")[0]\n",
    "            if not any(domain in url for domain in exclude_domains):\n",
    "                links.append(url)\n",
    "                if len(links) >= num_results:\n",
    "                    break\n",
    "    \n",
    "    return links\n",
    "\n",
    "# Function to convert a webpage to PDF\n",
    "def convert_to_pdf(url, output_path):\n",
    "    try:\n",
    "        pdfkit.from_url(url, output_path, configuration=pdfkit_config)\n",
    "        print(f\"Converted {url} to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {url}: {e}\")\n",
    "\n",
    "# Function to combine multiple PDFs into one\n",
    "def combine_pdfs(pdf_list, output_path):\n",
    "    merger = PdfMerger()\n",
    "    for pdf in pdf_list:\n",
    "        if os.path.exists(pdf):  # Ensure the file exists before appending\n",
    "            merger.append(pdf)\n",
    "    merger.write(output_path)\n",
    "    merger.close()\n",
    "\n",
    "# Define the search query\n",
    "name = \"Ravi Kumar S\"\n",
    "role = \"CEO\"\n",
    "company = \"Cognizant\"\n",
    "query = f\"{name} {role} {company}\"\n",
    "\n",
    "# Desired output directory\n",
    "output_directory = r\"C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get the top 20 search result links\n",
    "top_links = get_search_results(query, num_results=20)\n",
    "\n",
    "# Convert each link to PDF\n",
    "pdf_files = []\n",
    "for i, link in enumerate(top_links, 1):\n",
    "    pdf_path = os.path.join(output_directory, f\"result_{i}.pdf\")\n",
    "    convert_to_pdf(link, pdf_path)\n",
    "    pdf_files.append(pdf_path)\n",
    "\n",
    "# Combine all PDFs into one\n",
    "combined_pdf_path = os.path.join(output_directory, \"combined_results.pdf\")\n",
    "combine_pdfs(pdf_files, combined_pdf_path)\n",
    "\n",
    "print(f\"Combined PDF saved to {combined_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd73f1-e547-4ba6-9146-5efa96980b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New code targeting specific websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e0a93-b319-4699-ae1b-64110d43c6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfkit\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "# Path to wkhtmltopdf executable\n",
    "path_to_wkhtmltopdf = r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe'\n",
    "pdfkit_config = pdfkit.configuration(wkhtmltopdf=path_to_wkhtmltopdf)\n",
    "\n",
    "# Function to get search results\n",
    "async def get_search_results(query, num_results=30):\n",
    "    search_url = \"https://www.google.com/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(search_url, params=params) as response:\n",
    "            response_text = await response.text()\n",
    "            soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    \n",
    "    target_domains = [\n",
    "        \"linkedin.com\", \"twitter.com\", \"facebook.com\",\n",
    "        \"instagram.com\", \"pinterest.com\", \"tumblr.com\",\n",
    "        \"company website\", \"news\", \"business information\",\n",
    "        \"people search\", \"whitepages.com\", \"pipl.com\"\n",
    "    ]\n",
    "    \n",
    "    links = []\n",
    "    for item in soup.find_all('a'):\n",
    "        href = item.get('href')\n",
    "        if href and \"/url?q=\" in href:\n",
    "            url = href.split(\"/url?q=\")[1].split(\"&sa=U\")[0]\n",
    "            if any(domain in url for domain in target_domains):\n",
    "                links.append(url)\n",
    "                if len(links) >= num_results:\n",
    "                    break\n",
    "    \n",
    "    return links\n",
    "\n",
    "# Function to convert a webpage to PDF\n",
    "async def convert_to_pdf(url, output_path):\n",
    "    try:\n",
    "        pdfkit.from_url(url, output_path, configuration=pdfkit_config)\n",
    "        print(f\"Converted {url} to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {url}: {e}\")\n",
    "\n",
    "# Function to combine multiple PDFs into one\n",
    "def combine_pdfs(pdf_list, output_path):\n",
    "    merger = PdfMerger()\n",
    "    for pdf in pdf_list:\n",
    "        if os.path.exists(pdf):  # Ensure the file exists before appending\n",
    "            merger.append(pdf)\n",
    "    merger.write(output_path)\n",
    "    merger.close()\n",
    "\n",
    "# Function to delete individual PDFs after merging\n",
    "def delete_pdfs(pdf_list):\n",
    "    for pdf in pdf_list:\n",
    "        if os.path.exists(pdf):\n",
    "            os.remove(pdf)\n",
    "            print(f\"Deleted {pdf}\")\n",
    "\n",
    "# Define the search query\n",
    "name = \"Ravi Kumar S\"\n",
    "role = \"CEO\"\n",
    "company = \"Cognizant\"\n",
    "details = \"Biography\"\n",
    "query = f\"{name} {role} {company} {details}\"\n",
    "\n",
    "# Desired output directory\n",
    "output_directory = r\"C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Asynchronous main function to manage tasks\n",
    "async def main():\n",
    "    # Get the top 30 search result links\n",
    "    top_links = await get_search_results(query, num_results=30)\n",
    "\n",
    "    # Convert each link to PDF\n",
    "    pdf_files = []\n",
    "    tasks = []\n",
    "    for i, link in enumerate(top_links, 1):\n",
    "        pdf_path = os.path.join(output_directory, f\"result_{i}.pdf\")\n",
    "        tasks.append(convert_to_pdf(link, pdf_path))\n",
    "        pdf_files.append(pdf_path)\n",
    "\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "    # Combine all PDFs into one\n",
    "    combined_pdf_path = os.path.join(output_directory, \"combined_results.pdf\")\n",
    "    combine_pdfs(pdf_files, combined_pdf_path)\n",
    "\n",
    "    # Delete individual PDFs\n",
    "    delete_pdfs(pdf_files)\n",
    "\n",
    "    print(f\"Combined PDF saved to {combined_pdf_path}\")\n",
    "\n",
    "# Create an event loop if one doesn't already exist\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # If event loop is already running, execute main directly\n",
    "    await main()\n",
    "else:\n",
    "    # If no event loop is running, run main within a new event loop\n",
    "    loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60047491-d7bb-4ace-9a9e-487f3cfeb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new code without htmltopdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73fcab7d-fee4-4ee2-a8e2-532e42c2966f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 918, in _parseRuleset\n",
      "    src, selectors = self._parseSelectorGroup(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 928, in _parseSelectorGroup\n",
      "    src, selector = self._parseSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 942, in _parseSelector\n",
      "    src, selector = self._parseSimpleSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 999, in _parseSimpleSelector\n",
      "    src, selector = self._parseSelectorPseudo(src, selector)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1080, in _parseSelectorPseudo\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Selector Pseudo Function closing ')' not found:: (':not(', '[href]):not([tabinde')\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 899, in _parseAtIdent\n",
      "    src, declarations = self._parseDeclarationGroup(src)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1120, in _parseDeclarationGroup\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Declaration group closing '}' not found:: ('{0', '%{-webkit-transform:')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 561, in _parseStylesheet\n",
      "    src, atResults = self._parseAtKeyword(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 692, in _parseAtKeyword\n",
      "    src, result = self._parseAtIdent(src)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 902, in _parseAtIdent\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 919, in _parseRuleset\n",
      "    src, properties = self._parseDeclarationGroup(src.lstrip())\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1120, in _parseDeclarationGroup\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Declaration group closing '}' not found:: ('{0', '%{-webkit-transform:')\n",
      "@fontface, unknown value font-weight '100'\n",
      "\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 523, in open_for_read\n",
      "    return open_for_read_by_name(name,mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 463, in open_for_read_by_name\n",
      "    return open(name,mode)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\jvsgp\\\\AppData\\\\Local\\\\Temp\\\\tmp4xgsay16'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 530, in open_for_read\n",
      "    return BytesIO((datareader if name[:5].lower()=='data:' else rlUrlRead)(name))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 476, in rlUrlRead\n",
      "    return urlopen(name).read()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 541, in _open\n",
      "    return self._call_chain(self.handle_open, 'unknown',\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 1419, in unknown_open\n",
      "    raise URLError('unknown url type: %s' % type)\n",
      "urllib.error.URLError: <urlopen error unknown url type: c>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 151, in TTFOpenFile\n",
      "    f = open_for_read(fn,'rb')\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 532, in open_for_read\n",
      "    raise IOError('Cannot open resource \"%s\"' % name)\n",
      "OSError: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp4xgsay16\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 561, in _parseStylesheet\n",
      "    src, atResults = self._parseAtKeyword(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 685, in _parseAtKeyword\n",
      "    src, result = self._parseAtFontFace(src)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 866, in _parseAtFontFace\n",
      "    result = [self.cssBuilder.atFontFace(properties)]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 221, in atFontFace\n",
      "    self.c.loadFont(names, src, bold=bold, italic=italic)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 1107, in loadFont\n",
      "    file = TTFont(fullFontName, filename)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1192, in __init__\n",
      "    self.face = TTFontFace(filename, validate=validate, subfontIndex=subfontIndex)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1073, in __init__\n",
      "    TTFontFile.__init__(self, filename, validate=validate, subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 439, in __init__\n",
      "    TTFontParser.__init__(self, file, validate=validate,subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 175, in __init__\n",
      "    self.readFile(file)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 251, in readFile\n",
      "    self.filename, f = TTFOpenFile(f)\n",
      "                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 161, in TTFOpenFile\n",
      "    raise TTFError('Can\\'t open file \"%s\"' % fn)\n",
      "reportlab.pdfbase.ttfonts.TTFError: Can't open file \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp4xgsay16\"\n",
      "@fontface, unknown value font-weight '100'\n",
      "\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 523, in open_for_read\n",
      "    return open_for_read_by_name(name,mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 463, in open_for_read_by_name\n",
      "    return open(name,mode)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\jvsgp\\\\AppData\\\\Local\\\\Temp\\\\tmpn5xvonnd'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 530, in open_for_read\n",
      "    return BytesIO((datareader if name[:5].lower()=='data:' else rlUrlRead)(name))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 476, in rlUrlRead\n",
      "    return urlopen(name).read()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 541, in _open\n",
      "    return self._call_chain(self.handle_open, 'unknown',\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 1419, in unknown_open\n",
      "    raise URLError('unknown url type: %s' % type)\n",
      "urllib.error.URLError: <urlopen error unknown url type: c>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 151, in TTFOpenFile\n",
      "    f = open_for_read(fn,'rb')\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 532, in open_for_read\n",
      "    raise IOError('Cannot open resource \"%s\"' % name)\n",
      "OSError: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmpn5xvonnd\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 561, in _parseStylesheet\n",
      "    src, atResults = self._parseAtKeyword(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 685, in _parseAtKeyword\n",
      "    src, result = self._parseAtFontFace(src)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 866, in _parseAtFontFace\n",
      "    result = [self.cssBuilder.atFontFace(properties)]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 221, in atFontFace\n",
      "    self.c.loadFont(names, src, bold=bold, italic=italic)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 1107, in loadFont\n",
      "    file = TTFont(fullFontName, filename)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1192, in __init__\n",
      "    self.face = TTFontFace(filename, validate=validate, subfontIndex=subfontIndex)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1073, in __init__\n",
      "    TTFontFile.__init__(self, filename, validate=validate, subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 439, in __init__\n",
      "    TTFontParser.__init__(self, file, validate=validate,subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 175, in __init__\n",
      "    self.readFile(file)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 251, in readFile\n",
      "    self.filename, f = TTFOpenFile(f)\n",
      "                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 161, in TTFOpenFile\n",
      "    raise TTFError('Can\\'t open file \"%s\"' % fn)\n",
      "reportlab.pdfbase.ttfonts.TTFError: Can't open file \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmpn5xvonnd\"\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 919, in _parseRuleset\n",
      "    src, properties = self._parseDeclarationGroup(src.lstrip())\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1120, in _parseDeclarationGroup\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Declaration group closing '}' not found:: ('{\\n\\tbackground: #FF3860;\\n\\t;\\n\\t', 'color: #fff;\\n\\tfont-s')\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage//ad_spaces/G6M7HcUVvwOXDeUsyVqKVwAjxsEI3fgXnhAZido0.gif' on attempt 1\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/front/assets/img/home/varindia-logo.png' on attempt 1\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/front/assets/img/home/varindia-logo.png' on attempt 2\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage//ad_spaces/9kgLXT1zCGwz1dMGtioflNoFnZf3P3twRzVNXaPV.jpg' on attempt 1\n",
      "Could not get image data from src attribute: /xtras/banner/25th-year-logo.gif\n",
      "'<img src=\"/xtras/banner/25th-year-logo.gif\" width=\"120\"/>'\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/uploads/2018/02/63c0f18eaadb2.jpg' on attempt 1\n",
      "Could not get image data from src attribute: /front/assets/img/banner/banner8.jpg\n",
      "'<img src=\"/front/assets/img/banner/banner8.jpg\" alt=\"\"/>'\n",
      "Attribute 'type' of wrong value, allowed is one of: ['text', 'hidden', 'checkbox']\n",
      "'<div class=\"form-group\"> <input type=\"email\" class=\"form-control input-lg mr-4\" id=\"email_address\" aria-describedby=\"emailHelp\" placeholder=\"Enter email\" name=\"email_address\" required=\"\"/> <button type=\"submit\" class=\"btn\" id=\"btnSubmit\">subscribe</button> </div>'\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/nhTXv6QHEJPzKdxWFOwmqGjavUK08hqv2nqzTnZ1.webp' on attempt 1\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/ZmusftRKBADOchFBEWCt8rrm4oSTf7VAVo5kE9lu.jpg' on attempt 1\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/ZmusftRKBADOchFBEWCt8rrm4oSTf7VAVo5kE9lu.jpg' on attempt 2\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/ZmusftRKBADOchFBEWCt8rrm4oSTf7VAVo5kE9lu.jpg' on attempt 3\n",
      "Could not get image data from src attribute: https://www.varindia.com/storage/news/2024/06/ZmusftRKBADOchFBEWCt8rrm4oSTf7VAVo5kE9lu.jpg\n",
      "'<img src=\"https://www.varindia.com/storage/news/2024/06/ZmusftRKBADOchFBEWCt8rrm4oSTf7VAVo5kE9lu.jpg\" alt=\"BharatGPT Is Bridging Language Barriers\" title=\"BharatGPT Is Bridging Language Barriers\"/>'\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/WiALsCGBmPHwwOBJCUThF4cObWsAozJT4jG0L561.jpg' on attempt 1\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/uploads/2018/02/6507e4064548a.jpg' on attempt 1\n",
      "Could not get image data from src attribute: /front/assets/img/banner/banner-side1.jpg\n",
      "'<img src=\"/front/assets/img/banner/banner-side1.jpg\" class=\"w-100\" alt=\"\"/>'\n",
      "Could not get image data from src attribute: /front/assets/img/banner/banner-side2.jpg\n",
      "'<img src=\"/front/assets/img/banner/banner-side2.jpg\" class=\"w-100\" alt=\"\"/>'\n",
      "Could not get image data from src attribute: /front/assets/img/banner/banner-side3.jpg\n",
      "'<img src=\"/front/assets/img/banner/banner-side3.jpg\" class=\"w-100\" alt=\"\"/>'\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/fh2uReMMj7Chp5WEjeLayuxkIy58WRbfiVbgSMuR.jpg' on attempt 1\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/nCgdNN29nDvOBQEsGCaLVXOWgxMO7zrAsdGZBHi4.jpg' on attempt 1\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/9WYleHicwZh1HuYzxV2ATuLNcWZuSQpfK1c6Jwsj.jpg' on attempt 1\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/9WYleHicwZh1HuYzxV2ATuLNcWZuSQpfK1c6Jwsj.jpg' on attempt 2\n",
      "TimeoutError: The read operation timed out while extracting data from NetworkFileUri: 'https://www.varindia.com/storage/news/2024/06/GsgvXZmdxVO0YNFFAwvOJtfry2nPZdCmiB1yV0Qi.jpg' on attempt 1\n",
      "Could not get image data from src attribute: /front/assets/img/banner/banner9.jpg\n",
      "'<img src=\"/front/assets/img/banner/banner9.jpg\" class=\"w-100\" alt=\"\"/>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted https://www.varindia.com/news/who-is-ravi-kumar-the-newly-appointed-ceo-of-cognizant to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_10.pdf\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 542, in _parseStylesheet\n",
      "    src = self.re_comment.sub(\"\", src)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 542, in _parseStylesheet\n",
      "    src = self.re_comment.sub(\"\", src)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 542, in _parseStylesheet\n",
      "    src = self.re_comment.sub(\"\", src)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n",
      "Could not get image data from src attribute: /content/dam/prnewswire/homepage/prn_cision_logo_desktop.png\n",
      "'<img class=\"img-responsive \" src=\"/content/dam/prnewswire/homepage/prn_cision_logo_desktop.png\" title=\"Cision PR Newswire: news distribution, targeting and monitoring home\" alt=\"Cision PR Newswire: news distribution, targeting and monitoring home\" loading=\"lazy\" onerror=\"this.onerror=null; this.src=\\'\\'\"/>'\n",
      "Could not get image data from src attribute: /content/dam/prnewswire/homepage/prn_cision_logo_mobile.png\n",
      "'<img class=\"img-responsive \" src=\"/content/dam/prnewswire/homepage/prn_cision_logo_mobile.png\" title=\"PR Newswire: news distribution, targeting and monitoring\" alt=\"PR Newswire: news distribution, targeting and monitoring\"/>'\n",
      "Attribute 'src' must be set!\n",
      "'<a role=\"button\" href=\"#\" class=\"tablogofocus\"> <img class=\"img-responsive\" title=\"New Cognizant Logo (PRNewsfoto/Cognizant)\" data-getimg=\"https://mma.prnewswire.com/media/1794711/Cognizant_Logo.jpg?w=200\" alt=\"New Cognizant Logo (PRNewsfoto/Cognizant)\" loading=\"lazy\"/></a>'\n",
      "The src attribute of image tag is empty!\n",
      "'<img class=\"img-responsive\" title=\"New Cognizant Logo (PRNewsfoto/Cognizant)\" data-getimg=\"https://mma.prnewswire.com/media/1794711/Cognizant_Logo.jpg?w=200\" alt=\"New Cognizant Logo (PRNewsfoto/Cognizant)\" loading=\"lazy\"/>'\n",
      "Attribute 'src' must be set!\n",
      "'<div class=\"TCimg\"><img data-src=\"data:image/jpg;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYAQAAAACWHaVxAAADkUlEQVR4Xu3XUYrrMAyF4UAWlq1nYYXcSkeS3QwXxo3m7T+E4MjS53kxZbarL9u98CBYa8FaC9ZasNaCtRastWCtBWstWGvBWgvWWrDWgrWWsF5b5fDCuVvx8MeyWyWK790t69MIFtZ9BOtbK741vHv3JL4riokO2XObxcIaI1pgfWu9B9QkwotW8eWNGGfkiAULC6vd+iRsSz3XdOFvI9rGwsJqt/Tpb4tzSm0ZioWF9XdWLdSRd/j9tqeG/VNtY0QLrAvrNot1fWdVNPObZ4xg/ebBwro//7F+ZFzgn8dc032eg4V1D9ZXVg5oMgjnxo/rZb+49amFHiwsrE7L+6y7xuYZnaMtHZOnavfAwsLqtTSp7Wne6trVAZrMztqyYGFhNVmWl2/XBZ51v8zxXH6SzisdCwury6p5T0ExucdZGqtPVaxTwcJSBeuhpY3d+3z+cq4+bcahqMehXlT/hYWF1We94m7bXnGazxhRh9XZFSwsrC4rW0/Ni9ako7W23alhcFhYWC1Wdhun6z3RVpl7VMyFbWFhxRZWTD6ysvW9cfpdtbdu8lzPi60DVK8iFhZWj5VjNvk5M4reVvMWFStYWFgt1vUxrwxCF9t7VLdHnTOHhYVl6bBSOa6cUXUWvWjufHBxWBYsrON6bvmNjQ21urjpH07putWqe9Rm7wsLC6vPyks7UpdWhDecIibxqHmsCFbNY0VWLYOmxKcTOkDz9dRhYxALC2vkgfXKm1x9nsNbrVv1z2HV1WbBOrCwmqwctrGJiOhz7kzlxMKKTiztPba8qbaVM5VqMNEV9dh5Uz8WFlaXdWuKt+uKtuxINWfbCBYWVov1youdi80h6UXfFrae/gIsLF9jNVjvYduo1lKSPusAJ3SwgoWF1Wsd2RQbHvv0evXEpM7WqRUsLKwuK6HY1mSujfhhhVjHY2FhNVq1kWPWOtM6zHeUcd6FhYXVZM2R4n32+LC9dZKKXp8PsGBhYXmeWjkfhIo+r4EatvxEFSwsrCYrSvPiFb+jp8+PXRe1iGYFCwury1KHLw6ft/ceW1Hc4xEX/VhYWH9qqUOVcnOyFpFaY2FFsDqtbbcBQdEqRfV9GtFawTq0lW8srK+tWjg6Dxx+n0WfeZ6t9/zpVbCwsJqsysew7vn+cYaGrWF3OiksLKycf2a1BGstWGvBWgvWWrDWgrUWrLVgrQVrLVhrwVoL1lqw1tJp/QNt+fWm3FjU0gAAAABJRU5ErkJggg==\"/></div>'\n",
      "The src attribute of image tag is empty!\n",
      "'<img data-src=\"data:image/jpg;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYAQAAAACWHaVxAAADkUlEQVR4Xu3XUYrrMAyF4UAWlq1nYYXcSkeS3QwXxo3m7T+E4MjS53kxZbarL9u98CBYa8FaC9ZasNaCtRastWCtBWstWGvBWgvWWrDWgrWWsF5b5fDCuVvx8MeyWyWK790t69MIFtZ9BOtbK741vHv3JL4riokO2XObxcIaI1pgfWu9B9QkwotW8eWNGGfkiAULC6vd+iRsSz3XdOFvI9rGwsJqt/Tpb4tzSm0ZioWF9XdWLdSRd/j9tqeG/VNtY0QLrAvrNot1fWdVNPObZ4xg/ebBwro//7F+ZFzgn8dc032eg4V1D9ZXVg5oMgjnxo/rZb+49amFHiwsrE7L+6y7xuYZnaMtHZOnavfAwsLqtTSp7Wne6trVAZrMztqyYGFhNVmWl2/XBZ51v8zxXH6SzisdCwury6p5T0ExucdZGqtPVaxTwcJSBeuhpY3d+3z+cq4+bcahqMehXlT/hYWF1We94m7bXnGazxhRh9XZFSwsrC4rW0/Ni9ako7W23alhcFhYWC1Wdhun6z3RVpl7VMyFbWFhxRZWTD6ysvW9cfpdtbdu8lzPi60DVK8iFhZWj5VjNvk5M4reVvMWFStYWFgt1vUxrwxCF9t7VLdHnTOHhYVl6bBSOa6cUXUWvWjufHBxWBYsrON6bvmNjQ21urjpH07putWqe9Rm7wsLC6vPyks7UpdWhDecIibxqHmsCFbNY0VWLYOmxKcTOkDz9dRhYxALC2vkgfXKm1x9nsNbrVv1z2HV1WbBOrCwmqwctrGJiOhz7kzlxMKKTiztPba8qbaVM5VqMNEV9dh5Uz8WFlaXdWuKt+uKtuxINWfbCBYWVov1youdi80h6UXfFrae/gIsLF9jNVjvYduo1lKSPusAJ3SwgoWF1Wsd2RQbHvv0evXEpM7WqRUsLKwuK6HY1mSujfhhhVjHY2FhNVq1kWPWOtM6zHeUcd6FhYXVZM2R4n32+LC9dZKKXp8PsGBhYXmeWjkfhIo+r4EatvxEFSwsrCYrSvPiFb+jp8+PXRe1iGYFCwury1KHLw6ft/ceW1Hc4xEX/VhYWH9qqUOVcnOyFpFaY2FFsDqtbbcBQdEqRfV9GtFawTq0lW8srK+tWjg6Dxx+n0WfeZ6t9/zpVbCwsJqsysew7vn+cYaGrWF3OiksLKycf2a1BGstWGvBWgvWWrDWgrUWrLVgrQVrLVhrwVoL1lqw1tJp/QNt+fWm3FjU0gAAAABJRU5ErkJggg==\"/>'\n",
      "Attribute 'src' must be set!\n",
      "'<div class=\"TCimg\"><img data-src=\"data:image/jpg;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYAQAAAACWHaVxAAADkUlEQVR4Xu3XUYrrMAyF4UAWlq1nYYXcSkeS3QwXxo3m7T+E4MjS53kxZbarL9u98CBYa8FaC9ZasNaCtRastWCtBWstWGvBWgvWWrDWgrWWsF5b5fDCuVvx8MeyWyWK790t69MIFtZ9BOtbK741vHv3JL4riokO2XObxcIaI1pgfWu9B9QkwotW8eWNGGfkiAULC6vd+iRsSz3XdOFvI9rGwsJqt/Tpb4tzSm0ZioWF9XdWLdSRd/j9tqeG/VNtY0QLrAvrNot1fWdVNPObZ4xg/ebBwro//7F+ZFzgn8dc032eg4V1D9ZXVg5oMgjnxo/rZb+49amFHiwsrE7L+6y7xuYZnaMtHZOnavfAwsLqtTSp7Wne6trVAZrMztqyYGFhNVmWl2/XBZ51v8zxXH6SzisdCwury6p5T0ExucdZGqtPVaxTwcJSBeuhpY3d+3z+cq4+bcahqMehXlT/hYWF1We94m7bXnGazxhRh9XZFSwsrC4rW0/Ni9ako7W23alhcFhYWC1Wdhun6z3RVpl7VMyFbWFhxRZWTD6ysvW9cfpdtbdu8lzPi60DVK8iFhZWj5VjNvk5M4reVvMWFStYWFgt1vUxrwxCF9t7VLdHnTOHhYVl6bBSOa6cUXUWvWjufHBxWBYsrON6bvmNjQ21urjpH07putWqe9Rm7wsLC6vPyks7UpdWhDecIibxqHmsCFbNY0VWLYOmxKcTOkDz9dRhYxALC2vkgfXKm1x9nsNbrVv1z2HV1WbBOrCwmqwctrGJiOhz7kzlxMKKTiztPba8qbaVM5VqMNEV9dh5Uz8WFlaXdWuKt+uKtuxINWfbCBYWVov1youdi80h6UXfFrae/gIsLF9jNVjvYduo1lKSPusAJ3SwgoWF1Wsd2RQbHvv0evXEpM7WqRUsLKwuK6HY1mSujfhhhVjHY2FhNVq1kWPWOtM6zHeUcd6FhYXVZM2R4n32+LC9dZKKXp8PsGBhYXmeWjkfhIo+r4EatvxEFSwsrCYrSvPiFb+jp8+PXRe1iGYFCwury1KHLw6ft/ceW1Hc4xEX/VhYWH9qqUOVcnOyFpFaY2FFsDqtbbcBQdEqRfV9GtFawTq0lW8srK+tWjg6Dxx+n0WfeZ6t9/zpVbCwsJqsysew7vn+cYaGrWF3OiksLKycf2a1BGstWGvBWgvWWrDWgrUWrLVgrQVrLVhrwVoL1lqw1tJp/QNt+fWm3FjU0gAAAABJRU5ErkJggg==\"/></div>'\n",
      "The src attribute of image tag is empty!\n",
      "'<img data-src=\"data:image/jpg;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYAQAAAACWHaVxAAADkUlEQVR4Xu3XUYrrMAyF4UAWlq1nYYXcSkeS3QwXxo3m7T+E4MjS53kxZbarL9u98CBYa8FaC9ZasNaCtRastWCtBWstWGvBWgvWWrDWgrWWsF5b5fDCuVvx8MeyWyWK790t69MIFtZ9BOtbK741vHv3JL4riokO2XObxcIaI1pgfWu9B9QkwotW8eWNGGfkiAULC6vd+iRsSz3XdOFvI9rGwsJqt/Tpb4tzSm0ZioWF9XdWLdSRd/j9tqeG/VNtY0QLrAvrNot1fWdVNPObZ4xg/ebBwro//7F+ZFzgn8dc032eg4V1D9ZXVg5oMgjnxo/rZb+49amFHiwsrE7L+6y7xuYZnaMtHZOnavfAwsLqtTSp7Wne6trVAZrMztqyYGFhNVmWl2/XBZ51v8zxXH6SzisdCwury6p5T0ExucdZGqtPVaxTwcJSBeuhpY3d+3z+cq4+bcahqMehXlT/hYWF1We94m7bXnGazxhRh9XZFSwsrC4rW0/Ni9ako7W23alhcFhYWC1Wdhun6z3RVpl7VMyFbWFhxRZWTD6ysvW9cfpdtbdu8lzPi60DVK8iFhZWj5VjNvk5M4reVvMWFStYWFgt1vUxrwxCF9t7VLdHnTOHhYVl6bBSOa6cUXUWvWjufHBxWBYsrON6bvmNjQ21urjpH07putWqe9Rm7wsLC6vPyks7UpdWhDecIibxqHmsCFbNY0VWLYOmxKcTOkDz9dRhYxALC2vkgfXKm1x9nsNbrVv1z2HV1WbBOrCwmqwctrGJiOhz7kzlxMKKTiztPba8qbaVM5VqMNEV9dh5Uz8WFlaXdWuKt+uKtuxINWfbCBYWVov1youdi80h6UXfFrae/gIsLF9jNVjvYduo1lKSPusAJ3SwgoWF1Wsd2RQbHvv0evXEpM7WqRUsLKwuK6HY1mSujfhhhVjHY2FhNVq1kWPWOtM6zHeUcd6FhYXVZM2R4n32+LC9dZKKXp8PsGBhYXmeWjkfhIo+r4EatvxEFSwsrCYrSvPiFb+jp8+PXRe1iGYFCwury1KHLw6ft/ceW1Hc4xEX/VhYWH9qqUOVcnOyFpFaY2FFsDqtbbcBQdEqRfV9GtFawTq0lW8srK+tWjg6Dxx+n0WfeZ6t9/zpVbCwsJqsysew7vn+cYaGrWF3OiksLKycf2a1BGstWGvBWgvWWrDWgrUWrLVgrQVrLVhrwVoL1lqw1tJp/QNt+fWm3FjU0gAAAABJRU5ErkJggg==\"/>'\n",
      "Attribute 'type' of wrong value, allowed is one of: ['circle', 'disk', 'square']\n",
      "'<div class=\"col-lg-10 col-lg-offset-1\"> <ul type=\"disc\"> <li><i>Former Infosys President brings 20+ years of experience in the consulting, process, and technology transformation space to CEO role</i></li> <li><i><span class=\"xn-person\">Stephen J. Rohleder</span> appointed Chair of the Board</i></li> <li><i>Leadership transition supports initiative to accelerate growth</i></li> <li><i>Company updates fourth quarter and full-year 2022 guidance</i></li> </ul><p><span class=\"legendSpanClass\"><span'\n",
      "Attribute 'src' must be set!\n",
      "'<a href=\"#\" class=\"tabfocus\" role=\"button\"><img title=\"Ravi Kumar S, Chief Executive Officer of Cognizant\" data-getimg=\"https://mma.prnewswire.com/media/1981805/Cognizant_Ravi_Kumar_S_CEO.jpg?w=600\" id=\"imageid_2\" alt=\"Ravi Kumar S, Chief Executive Officer of Cognizant\" class=\"gallery-thumb img-responsive\" rel=\"newsImage\" itemprop=\"contentUrl\" loading=\"lazy\"/></a>'\n",
      "The src attribute of image tag is empty!\n",
      "'<img title=\"Ravi Kumar S, Chief Executive Officer of Cognizant\" data-getimg=\"https://mma.prnewswire.com/media/1981805/Cognizant_Ravi_Kumar_S_CEO.jpg?w=600\" id=\"imageid_2\" alt=\"Ravi Kumar S, Chief Executive Officer of Cognizant\" class=\"gallery-thumb img-responsive\" rel=\"newsImage\" itemprop=\"contentUrl\" loading=\"lazy\"/>'\n",
      "Could not get image data from src attribute: https://rt.prnewswire.com/rt.gif?NewsItemId=NY84396&Transmission_Id=202301120830PR_NEWS_USPR_____NY84396&DateId=20230112\n",
      "'<img alt=\"\" src=\"https://rt.prnewswire.com/rt.gif?NewsItemId=NY84396&amp;Transmission_Id=202301120830PR_NEWS_USPR_____NY84396&amp;DateId=20230112\" style=\"border:0px; width:1px; height:1px;\"/>'\n",
      "Could not get image data from src attribute: /content/dam/prnewswire/subject-and-industry-code-images/CPR.jpg\n",
      "'<img src=\"/content/dam/prnewswire/subject-and-industry-code-images/CPR.jpg\" alt=\"Image1\" title=\"\"/>'\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 542, in _parseStylesheet\n",
      "    src = self.re_comment.sub(\"\", src)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted https://www.prnewswire.com/news-releases/cognizant-appoints-ravi-kumar-s-as-chief-executive-officer-301720183.html to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_7.pdf\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n",
      "Converted https://www.gurufocus.com/news/2126749/cognizant-technology-solutions-corpctsh-2022-ceo-ravi-kumar-ss-shareholder-letter-driving-growth-and-fostering-talent to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_12.pdf\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n",
      "Failed to convert https://www.businesstoday.in/technology/news/story/cognizant-appoints-indian-origin-ravi-kumar-as-ceo-360029-2023-01-12: Selector Pseudo Function closing ')' not found:: (':not(', '.adtext){ min-height')\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 918, in _parseRuleset\n",
      "    src, selectors = self._parseSelectorGroup(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 928, in _parseSelectorGroup\n",
      "    src, selector = self._parseSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 951, in _parseSelector\n",
      "    src, selectorB = self._parseSimpleSelector(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 999, in _parseSimpleSelector\n",
      "    src, selector = self._parseSelectorPseudo(src, selector)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1080, in _parseSelectorPseudo\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Selector Pseudo Function closing ')' not found:: (':not(', '.always-enable-anima')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted https://www.facebook.com/ravi.s.50/ to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_5.pdf\n",
      "Failed to convert https://twitter.com/imravikumars%3Fref_src%3Dtwsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Eauthor: Cannot write to closing transport\n",
      "Failed to convert https://twitter.com/imravikumars/status/1799585515349434548%3Fref_src%3Dtwsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Etweet: Cannot write to closing transport\n",
      "Failed to convert https://www.linkedin.com/in/imravikumars: Response payload is not completed\n",
      "Failed to convert https://www.linkedin.com/posts/rajeev-chandrasekhar-971203257_mr-ravi-kumar-ceo-cognizant-called-on-me-activity-7141438052073127936-gv4M: Response payload is not completed\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n",
      "Failed to convert https://www.moneycontrol.com/news/business/cognizants-new-ceo-10-things-to-know-about-ravi-kumar-9856591.html: Selector Pseudo Function closing ')' not found:: (':not(', ':root) { overflow: h')\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@fontface, unknown value font-weight '400'\n",
      "\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 523, in open_for_read\n",
      "    return open_for_read_by_name(name,mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 463, in open_for_read_by_name\n",
      "    return open(name,mode)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\jvsgp\\\\AppData\\\\Local\\\\Temp\\\\tmp9mungikx'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 530, in open_for_read\n",
      "    return BytesIO((datareader if name[:5].lower()=='data:' else rlUrlRead)(name))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 476, in rlUrlRead\n",
      "    return urlopen(name).read()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 541, in _open\n",
      "    return self._call_chain(self.handle_open, 'unknown',\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\urllib\\request.py\", line 1419, in unknown_open\n",
      "    raise URLError('unknown url type: %s' % type)\n",
      "urllib.error.URLError: <urlopen error unknown url type: c>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 151, in TTFOpenFile\n",
      "    f = open_for_read(fn,'rb')\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\lib\\utils.py\", line 532, in open_for_read\n",
      "    raise IOError('Cannot open resource \"%s\"' % name)\n",
      "OSError: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp9mungikx\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 561, in _parseStylesheet\n",
      "    src, atResults = self._parseAtKeyword(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 685, in _parseAtKeyword\n",
      "    src, result = self._parseAtFontFace(src)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 866, in _parseAtFontFace\n",
      "    result = [self.cssBuilder.atFontFace(properties)]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 221, in atFontFace\n",
      "    self.c.loadFont(names, src, bold=bold, italic=italic)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 1107, in loadFont\n",
      "    file = TTFont(fullFontName, filename)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1192, in __init__\n",
      "    self.face = TTFontFace(filename, validate=validate, subfontIndex=subfontIndex)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 1073, in __init__\n",
      "    TTFontFile.__init__(self, filename, validate=validate, subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 439, in __init__\n",
      "    TTFontParser.__init__(self, file, validate=validate,subfontIndex=subfontIndex)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 175, in __init__\n",
      "    self.readFile(file)\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 251, in readFile\n",
      "    self.filename, f = TTFOpenFile(f)\n",
      "                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\reportlab\\pdfbase\\ttfonts.py\", line 161, in TTFOpenFile\n",
      "    raise TTFError('Can\\'t open file \"%s\"' % fn)\n",
      "reportlab.pdfbase.ttfonts.TTFError: Can't open file \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp9mungikx\"\n",
      "wrong attributes for <pdf:font>\n",
      "\n",
      "wrong attributes for <pdf:font>\n",
      "\n",
      "wrong attributes for <pdf:font>\n",
      "\n",
      "wrong attributes for <pdf:font>\n",
      "\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 899, in _parseAtIdent\n",
      "    src, declarations = self._parseDeclarationGroup(src)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1120, in _parseDeclarationGroup\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Declaration group closing '}' not found:: ('{0', '%{-webkit-transform:')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 561, in _parseStylesheet\n",
      "    src, atResults = self._parseAtKeyword(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 692, in _parseAtKeyword\n",
      "    src, result = self._parseAtIdent(src)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 902, in _parseAtIdent\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 919, in _parseRuleset\n",
      "    src, properties = self._parseDeclarationGroup(src.lstrip())\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 1120, in _parseDeclarationGroup\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Declaration group closing '}' not found:: ('{0', '%{-webkit-transform:')\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 918, in _parseRuleset\n",
      "    src, selectors = self._parseSelectorGroup(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 928, in _parseSelectorGroup\n",
      "    src, selector = self._parseSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 942, in _parseSelector\n",
      "    src, selector = self._parseSimpleSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 981, in _parseSimpleSelector\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Selector name or qualifier expected:: \"\\ufeff\\n.block-wrapper {\\n    font-family: 'Lat\"\n",
      "Error while parsing CSS file\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\context.py\", line 519, in parseExternal\n",
      "    result = self.parse(cssFile.getData())\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 458, in parse\n",
      "    src, stylesheet = self._parseStylesheet(src)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 566, in _parseStylesheet\n",
      "    src, ruleset = self._parseRuleset(src)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 918, in _parseRuleset\n",
      "    src, selectors = self._parseSelectorGroup(src)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 928, in _parseSelectorGroup\n",
      "    src, selector = self._parseSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 942, in _parseSelector\n",
      "    src, selector = self._parseSimpleSelector(src)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jvsgp\\anaconda3\\Lib\\site-packages\\xhtml2pdf\\w3c\\cssParser.py\", line 981, in _parseSimpleSelector\n",
      "    raise self.ParseError(msg, src, ctxsrc)\n",
      "xhtml2pdf.w3c.cssParser.CSSParseError: Selector name or qualifier expected:: '\\ufeff.daijiFirstMenu {\\n    margin: 0px;\\n    '\n",
      "Attribute 'type' of wrong value, allowed is one of: ['text', 'hidden', 'checkbox']\n",
      "'<div class=\"navbar-form navbar-left\" role=\"search\"> <input type=\"submit\" value=\"Search\" id=\"search\" class=\"btn btn-danger btn-flat form-control\" style=\"width:80px;\"/> </div>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted https://www.daijiworld.com/news/newsDisplay%3FnewsID%3D1173029 to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_13.pdf\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n",
      "Converted https://twitter.com/imravikumars/status/1799585515349434548%3Fref_src%3Dtwsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Etweet to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_3.pdf\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmplmbvl_fa\"\n",
      "Error: Cannot open resource: Cannot open resource \"C:\\Users\\jvsgp\\AppData\\Local\\Temp\\tmp6ubq4sfg\"\n",
      "Converted https://twitter.com/amitaravikumar%3Flang%3Den to C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\\result_8.pdf\n"
     ]
    },
    {
     "ename": "EmptyFileError",
     "evalue": "Cannot read an empty file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyFileError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 140\u001b[0m\n\u001b[0;32m    137\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# If event loop is already running, execute main directly\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# If no event loop is running, run main within a new event loop\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     loop\u001b[38;5;241m.\u001b[39mrun_until_complete(main())\n",
      "Cell \u001b[1;32mIn[11], line 129\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Combine all PDFs into one\u001b[39;00m\n\u001b[0;32m    128\u001b[0m combined_pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_results.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 129\u001b[0m combine_pdfs(pdf_files, combined_pdf_path)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Delete individual PDFs\u001b[39;00m\n\u001b[0;32m    132\u001b[0m delete_pdfs(pdf_files)\n",
      "Cell \u001b[1;32mIn[11], line 90\u001b[0m, in \u001b[0;36mcombine_pdfs\u001b[1;34m(pdf_list, output_path)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_list:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pdf):  \u001b[38;5;66;03m# Ensure the file exists before appending\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m         merger\u001b[38;5;241m.\u001b[39mappend(pdf)\n\u001b[0;32m     91\u001b[0m merger\u001b[38;5;241m.\u001b[39mwrite(output_path)\n\u001b[0;32m     92\u001b[0m merger\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_utils.py:417\u001b[0m, in \u001b[0;36mdeprecation_bookmark.<locals>.decoration.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     rename_kwargs(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs, aliases, fail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_merger.py:319\u001b[0m, in \u001b[0;36mPdfMerger.append\u001b[1;34m(self, fileobj, outline_item, pages, import_outline)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;129m@deprecation_bookmark\u001b[39m(bookmark\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutline_item\u001b[39m\u001b[38;5;124m\"\u001b[39m, import_bookmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport_outline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     import_outline: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    295\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    Identical to the :meth:`merge()<merge>` method, but assumes you want to\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    concatenate all pages onto the end of the file instead of specifying a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m        'bookmarks') from being imported by specifying this as ``False``.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpages), fileobj, outline_item, pages, import_outline)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_utils.py:417\u001b[0m, in \u001b[0;36mdeprecation_bookmark.<locals>.decoration.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     rename_kwargs(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs, aliases, fail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_merger.py:198\u001b[0m, in \u001b[0;36mPdfMerger.merge\u001b[1;34m(self, page_number, fileobj, outline_item, pages, import_outline, position)\u001b[0m\n\u001b[0;32m    194\u001b[0m stream, encryption_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(fileobj)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Create a new PdfReader instance using the stream\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# (either file or BytesIO or StringIO) created above\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m reader \u001b[38;5;241m=\u001b[39m PdfReader(stream, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrict)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mappend((stream, reader))\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encryption_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:1414\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_validation(stream)\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_eof_marker(stream)\n\u001b[0;32m   1416\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:1455\u001b[0m, in \u001b[0;36mPdfReader._basic_validation\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1453\u001b[0m stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mSEEK_END)\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell():\n\u001b[1;32m-> 1455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyFileError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot read an empty file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrict:\n\u001b[0;32m   1457\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mSEEK_SET)\n",
      "\u001b[1;31mEmptyFileError\u001b[0m: Cannot read an empty file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from xhtml2pdf import pisa\n",
    "from PyPDF2 import PdfMerger\n",
    "from reportlab.lib.utils import open_for_read\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "\n",
    "# Function to get search results\n",
    "async def get_search_results(query, num_results=30):\n",
    "    search_url = \"https://www.google.com/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(search_url, params=params) as response:\n",
    "            response_text = await response.text()\n",
    "            soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    \n",
    "    target_domains = [\n",
    "        \"linkedin.com\", \"twitter.com\", \"facebook.com\",\n",
    "        \"instagram.com\", \"pinterest.com\", \"tumblr.com\",\n",
    "        \"company website\", \"news\", \"business information\",\n",
    "        \"people search\", \"whitepages.com\", \"pipl.com\"\n",
    "    ]\n",
    "    \n",
    "    links = []\n",
    "    for item in soup.find_all('a'):\n",
    "        href = item.get('href')\n",
    "        if href and \"/url?q=\" in href:\n",
    "            url = href.split(\"/url?q=\")[1].split(\"&sa=U\")[0]\n",
    "            if any(domain in url for domain in target_domains):\n",
    "                links.append(url)\n",
    "                if len(links) >= num_results:\n",
    "                    break\n",
    "    \n",
    "    return links\n",
    "\n",
    "# Function to convert a webpage to PDF\n",
    "async def convert_to_pdf(url, output_path):\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                html_content = await response.text()\n",
    "\n",
    "        # Check if the HTML content is empty\n",
    "        if not html_content.strip():\n",
    "            print(f\"HTML content from {url} is empty.\")\n",
    "            return\n",
    "\n",
    "        # Load fonts\n",
    "        load_fonts()\n",
    "\n",
    "        # Write HTML content to PDF\n",
    "        with open(output_path, 'w+b') as result_file:\n",
    "            pisa_status = pisa.CreatePDF(html_content, dest=result_file)\n",
    "\n",
    "        if pisa_status.err:\n",
    "            print(f\"Failed to convert {url} to PDF\")\n",
    "        else:\n",
    "            print(f\"Converted {url} to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {url}: {e}\")\n",
    "\n",
    "# Function to load fonts\n",
    "def load_fonts():\n",
    "    font1 = load_font('C:\\\\Users\\\\jvsgp\\\\AppData\\\\Local\\\\Temp\\\\tmplmbvl_fa')\n",
    "    font2 = load_font('C:\\\\Users\\\\jvsgp\\\\AppData\\\\Local\\\\Temp\\\\tmp6ubq4sfg')\n",
    "\n",
    "def load_font(filename):\n",
    "    try:\n",
    "        with open_for_read(filename, 'rb') as f:\n",
    "            font = TTFont('myfont', f)\n",
    "            return font\n",
    "    except IOError as e:\n",
    "        print(\"Error: Cannot open resource:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    return None\n",
    "\n",
    "# Function to combine multiple PDFs into one\n",
    "def combine_pdfs(pdf_list, output_path):\n",
    "    merger = PdfMerger()\n",
    "    for pdf in pdf_list:\n",
    "        if os.path.exists(pdf):  # Ensure the file exists before appending\n",
    "            merger.append(pdf)\n",
    "    merger.write(output_path)\n",
    "    merger.close()\n",
    "\n",
    "# Function to delete individual PDFs after merging\n",
    "def delete_pdfs(pdf_list):\n",
    "    for pdf in pdf_list:\n",
    "        if os.path.exists(pdf):\n",
    "            os.remove(pdf)\n",
    "            print(f\"Deleted {pdf}\")\n",
    "\n",
    "# Define the search query\n",
    "name = \"Ravi Kumar S\"\n",
    "role = \"CEO\"\n",
    "company = \"Cognizant\"\n",
    "details = \"Biography\"\n",
    "query = f\"{name} {role} {company} {details}\"\n",
    "\n",
    "# Desired output directory\n",
    "output_directory = r\"C:\\Users\\jvsgp\\OneDrive\\Desktop\\sasi\\Web Scraping\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Asynchronous main function to manage tasks\n",
    "async def main():\n",
    "    # Get the top 30 search result links\n",
    "    top_links = await get_search_results(query, num_results=30)\n",
    "\n",
    "    # Convert each link to PDF\n",
    "    pdf_files = []\n",
    "    tasks = []\n",
    "    for i, link in enumerate(top_links, 1):\n",
    "        pdf_path = os.path.join(output_directory, f\"result_{i}.pdf\")\n",
    "        tasks.append(convert_to_pdf(link, pdf_path))\n",
    "        pdf_files.append(pdf_path)\n",
    "\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "    # Combine all PDFs into one\n",
    "    combined_pdf_path = os.path.join(output_directory, \"combined_results.pdf\")\n",
    "    combine_pdfs(pdf_files, combined_pdf_path)\n",
    "\n",
    "    # Delete individual PDFs\n",
    "    delete_pdfs(pdf_files)\n",
    "\n",
    "    print(f\"Combined PDF saved to {combined_pdf_path}\")\n",
    "\n",
    "# Create an event loop if one doesn't already exist\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    # If event loop is already running, execute main directly\n",
    "    await main()\n",
    "else:\n",
    "    # If no event loop is running, run main within a new event loop\n",
    "    loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb206e77-1da0-47de-9c27-677a9217f5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
